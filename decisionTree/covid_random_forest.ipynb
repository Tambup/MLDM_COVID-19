{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_random_forest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAAtCC5DUmurchQdf24P17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/MLDM_COVID-19/blob/master/decisionTree/covid_random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bFYEsDnsmW6",
        "colab_type": "text"
      },
      "source": [
        "# COVID RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci8Rlg2csmW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e81ece9e-c192-4f2f-f677-8ae203e2d501"
      },
      "source": [
        "%autosave 30\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (30, 8)\n",
        "\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.metrics import r2_score, mean_squared_error, max_error\n",
        "from sklearn.ensemble import RandomForestRegressor \n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.externals.six import StringIO\n",
        "\n",
        "\n",
        "import pydotplus\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import os\n",
        "os.chdir(\"/content/drive/Shared drives/MLDM progetto/Datasets/dataset_finali\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(30000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 30 seconds\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ebc7533a7ae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/Shared drives/MLDM progetto/Datasets/dataset_finali\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shared drives/MLDM progetto/Datasets/dataset_finali'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M-VYAtrsmXN",
        "colab_type": "text"
      },
      "source": [
        "### MODELLO: preparazione dei datasets\n",
        "\n",
        "**Carichiamo** il dataset ed impostiamo il **random state**. Trasformiamo l'attributo nominale in numerico.\n",
        "\n",
        "**Dividiamo** il dataset in:\n",
        "* **training** set\n",
        "* **testing** set\n",
        "\n",
        "Proviamo utilizzando l'**80%** dei records per il training set ed il restante per il testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbKzFq8smXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "outputId": "9645e3db-424b-4c19-d489-976bf4f7d8c0"
      },
      "source": [
        "df_2 = pd.read_csv(\"dataset_finale_medie_2_week_rnd1.csv\", parse_dates=[\"Data\"], infer_datetime_format=True)\n",
        "df_0 = pd.read_csv(\"dataset_finale_medie_rnd1.csv\", parse_dates=[\"Data\"], infer_datetime_format=True)\n",
        "\n",
        "rnd_state = 12345\n",
        "predictor_columns = [\n",
        "                     'pass_Ammoniaca', \n",
        "                     'pass_Benzene',\n",
        "       'pass_Biossido di Azoto', \n",
        "       'pass_Biossido di Zolfo',\n",
        "       'pass_Monossido di Azoto', \n",
        "       'pass_Monossido di Carbonio',\n",
        "       'pass_Ossidi di Azoto', \n",
        "       'pass_Ozono', \n",
        "       'pass_PM10 (SM2005)',\n",
        "       'pass_Particelle sospese PM2.5',\n",
        "       'pass_Radiazione Globale', \n",
        "       'pass_Temperatura',\n",
        "       'pass_deceduti',\n",
        "       'pass_nuovi_positivi',\n",
        "       'pass_ricoverati_con_sintomi', \n",
        "       'pass_tamponi']\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-a4430d0f7674>\", line 1, in <module>\n",
            "    df_2 = pd.read_csv(\"dataset_finale_medie_2_week_rnd1.csv\", parse_dates=[\"Data\"], infer_datetime_format=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 448, in _read\n",
            "    parser = TextFileReader(fp_or_buf, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 880, in __init__\n",
            "    self._make_engine(self.engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
            "    self._engine = CParserWrapper(self.f, **self.options)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
            "    self._reader = parsers.TextReader(src, **kwds)\n",
            "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
            "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
            "FileNotFoundError: [Errno 2] File dataset_finale_medie_2_week_rnd1.csv does not exist: 'dataset_finale_medie_2_week_rnd1.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD_B4xnfG7RE",
        "colab_type": "text"
      },
      "source": [
        "**Prepariamo** il **training** set ed il **test** set per il data set relativo all'interllo fra i **quattordici e sette giorni precedenti**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztIBwjr4G7hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_2 = df_2.sample(frac=0.70, random_state=rnd_state)\n",
        "test_2 = df_2.drop(train_2.index)\n",
        "\n",
        "train_X_2 = train_2[predictor_columns]\n",
        "train_y_2 = train_2[\"fut1_nuovi_positivi\"]\n",
        "\n",
        "test_X_2 = test_2[predictor_columns]\n",
        "test_y_2 = test_2[\"fut1_nuovi_positivi\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G18UYlfHLrMR",
        "colab_type": "text"
      },
      "source": [
        "**Prepariamo** il **training** set ed il **test** set per il data set relativo all'interllo dei **quattordici giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xasaiKwLpSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_0 = df_0.sample(frac=0.70, random_state=rnd_state)\n",
        "test_0 = df_0.drop(train_0.index)\n",
        "\n",
        "train_X_0 = train_0[predictor_columns]\n",
        "train_y_0 = train_0[\"fut1_nuovi_positivi\"]\n",
        "\n",
        "test_X_0 = test_0[predictor_columns]\n",
        "test_y_0 = test_0[\"fut1_nuovi_positivi\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHAzWfwQsmXo",
        "colab_type": "text"
      },
      "source": [
        "### MODELLO: training ###\n",
        "\n",
        "Creiamo il **regressore** basato su alberi di decisione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVptjQSysmXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create regressor object \n",
        "forest_regressor = RandomForestRegressor(bootstrap=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_PZ-3oSsmXx",
        "colab_type": "text"
      },
      "source": [
        "Definiamo la **Pipeline**, come abbiamo fatto per le ANN:\n",
        "* imputer\n",
        "* addestramento del modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3F5lIuQsmXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([(\"imp\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")), \n",
        "                     (\"rf\", forest_regressor)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cey1HTIsmX7",
        "colab_type": "text"
      },
      "source": [
        "Prepariamo gli **iper-parametri** per la grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ZFmOKBsmX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators_list = [100,150,50]\n",
        "criterion_list = [\"mse\", \"mae\"]\n",
        "max_depth_list = [None, 5, 6]\n",
        "min_samples_split_list = [2, 3]\n",
        "min_samples_split_leaf_list = [3,5]\n",
        "min_weight_fraction_leaf_list = [0.0, 0.1]\n",
        "max_features_list = [\"auto\", \"sqrt\", \"log2\"]\n",
        "max_leaf_nodes_list = [None, 10, 25]\n",
        "min_impurity_decrease_list = [0.0, 0.1]\n",
        "\n",
        "param_grid = {\"dtr__criterion\": criterion_list,\n",
        "              \"dtr__max_depth\": max_depth_list,\n",
        "              \"dtr__min_samples_split\": min_samples_split_list,\n",
        "              \"dtr__min_samples_leaf\": min_samples_split_leaf_list,\n",
        "              \"dtr__min_weight_fraction_leaf\": min_weight_fraction_leaf_list,\n",
        "              \"dtr__max_features\": max_features_list,\n",
        "              \"dtr__max_leaf_nodes\": max_leaf_nodes_list,\n",
        "              \"dtr__min_impurity_decrease\": min_impurity_decrease_list}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH2pO-mNsmYD",
        "colab_type": "text"
      },
      "source": [
        "**Addestriamo** il regressore mediante **grid search** e **k-fold** cross validation. Anche questa volta, utilizziamo k non superiore a 5 in modo da avere degli insiemi statisticamente significativi (con almeno 30 elementi)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDYAgpsIHd-d",
        "colab_type": "text"
      },
      "source": [
        "Relativo fra **quattordici e sette giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMthr73YHwHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold_splits = 4\n",
        "grid_regressor_2 = GridSearchCV(estimator=pipeline,  \n",
        "                              n_jobs=-1, \n",
        "                              verbose=1,\n",
        "                              return_train_score=True,\n",
        "                              cv=KFold(n_splits=kfold_splits, shuffle=True, random_state=rnd_state),\n",
        "                              param_grid=param_grid)\n",
        "\n",
        "grid_regressor_2.fit(train_X_2, train_y_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeySQCLuL-06",
        "colab_type": "text"
      },
      "source": [
        "Relativo ai **quattordici giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJtZ4GoRMIFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold_splits = 4\n",
        "grid_regressor_0 = GridSearchCV(estimator=pipeline,  \n",
        "                              n_jobs=-1, \n",
        "                              verbose=1,\n",
        "                              return_train_score=True,\n",
        "                              cv=KFold(n_splits=kfold_splits, shuffle=True, random_state=rnd_state),\n",
        "                              param_grid=param_grid)\n",
        "\n",
        "grid_regressor_0.fit(train_X_0, train_y_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxX9u-kysmYL",
        "colab_type": "text"
      },
      "source": [
        "### MODELLO: testing ###\n",
        "\n",
        "Processiamo i dati di test allo stesso modo del training e procediamo alla fase di testing del **miglior regressore**, addestrato mediante grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62DvyFUpICsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_regressor_2 = grid_regressor_2.best_estimator_[\"rf\"]\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "imputer = imputer.fit(test_X_2)\n",
        "test_X_imp = imputer.transform(test_X_2)\n",
        "\n",
        "predicted_2 = best_regressor_2.predict(test_X_imp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuA58oN2MWH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_regressor_0 = grid_regressor_0.best_estimator_[\"rf\"]\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "imputer = imputer.fit(test_X_0)\n",
        "test_X_imp = imputer.transform(test_X_0)\n",
        "\n",
        "predicted_0 = best_regressor_0.predict(test_X_imp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvKCPAyUIHUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_triks=df_2.loc[list(test_X_2.index),['Data']]\n",
        "plt.plot(predicted_2, label=\"nuovi_positivi_pred\")\n",
        "plt.plot(test_y_2.values, label=\"nuovi_positivi\")\n",
        "plt.xticks(np.arange(x_triks.shape[0]), (x_triks.values), rotation=90)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title(\"Risultati del DTregressor addestrato con grid search per i dati fra i quattordici e sette giorni precedenti\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UF85QulMomb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_triks=df_0.loc[list(test_X_0.index),['Data']]\n",
        "plt.plot(predicted_0, label=\"nuovi_positivi_pred\")\n",
        "plt.plot(test_y_0.values, label=\"nuovi_positivi\")\n",
        "plt.xticks(np.arange(x_triks.shape[0]), (x_triks.values), rotation=90)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title(\"Risultati del DTregressor addestrato con grid search per i dati fra i quattordici giorni precedenti\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdZmGllismYZ",
        "colab_type": "text"
      },
      "source": [
        "### MODELLO: valutazione ed osservazioni ###\n",
        "\n",
        "Vediamo le **caratteristiche** del miglior albero di decisione trovato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8WL2QsrJZf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_regressor_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kj0-m1xMrZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_regressor_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEkh1yo4smYi",
        "colab_type": "text"
      },
      "source": [
        "Si tratta di un DecisionTreeRegressor con splitter **random** e criterio di split **MAE** (Mean Absolute Error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBMPP8IQsmYj",
        "colab_type": "text"
      },
      "source": [
        "Calcoliamo alcune **misure di performance** per il regressore basato su alberi di decisione. Abbiamo scelto quelle a parer nostro più significative:\n",
        "* **R2**: coefficiente di determinazione\n",
        "* **RMSE**: root mean squared error\n",
        "* **MAX Error**: errore massimo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lzSqp31M8RH",
        "colab_type": "text"
      },
      "source": [
        "Relativo fra **quattordici e sette giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI2wbacmIRCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"R2: \\t\\t{r2_score(test_y_2, predicted_2):.3}\")\n",
        "print(f\"RMSE: \\t\\t{mean_squared_error(test_y_2, predicted_2, squared=False):.3}\")\n",
        "print(f\"MAX ERR: \\t{max_error(test_y_2, predicted_2)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pzpbz8VNCBi",
        "colab_type": "text"
      },
      "source": [
        "Relativo ai **quattordici giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lei6agH5NDlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"R2: \\t\\t{r2_score(test_y_0, predicted_0):.3}\")\n",
        "print(f\"RMSE: \\t\\t{mean_squared_error(test_y_0, predicted_0, squared=False):.3}\")\n",
        "print(f\"MAX ERR: \\t{max_error(test_y_0, predicted_0)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWImSTtUsmYv",
        "colab_type": "text"
      },
      "source": [
        "Possiamo **osservare** che le performance del miglior albero di decisione trovato sono abbastanza **buone**.\n",
        "\n",
        "**R2** è **0.893**, ampiamente superiore a 0.5 ed abbastanza vicino al massimo (1). Questo vuol dire che il modello spiega gran parte della varianza dei dati.\n",
        "\n",
        "**RMSE** è **59.7**, pertanto il nostro modello in media sbaglia il conteggio dei nuovi positivi di 60 unità. Seppur di primo acchitto sembri eccessivo, in realtà non lo è se si pensa che in alcune giornate sono stati registrati più di 1000 nuovi positivi.\n",
        "\n",
        "**MAX ERR** è **238**. Dal grafico si nota come in un preciso giorno il predittore sbagli parecchio. Questo errore molto pronunciato va ad influenzare negativamente l'RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvGtipXB1---",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "test=StringIO()\n",
        "tree.export_graphviz(best_regressor_0,out_file='test.dot',feature_names=predictor_columns)\n",
        "grap=pydotplus.graph_from_dot_file('test.dot')\n",
        "Image(grap.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9CfFdi72x6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "test=StringIO()\n",
        "tree.export_graphviz(best_regressor_2,out_file='test.dot',feature_names=predictor_columns)\n",
        "grap=pydotplus.graph_from_dot_file('test.dot')\n",
        "Image(grap.create_png())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udP-Ac3dsmYv",
        "colab_type": "text"
      },
      "source": [
        "### MODELLO: feature importance\n",
        "\n",
        "Visualizziamo la **feature importance** derivante dal training del miglior albero regressore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPvr48i3M9ZP",
        "colab_type": "text"
      },
      "source": [
        "Relativo fra **quattordici e sette giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNmjrJqJiqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importance = dict(zip(predictor_columns, best_regressor_2.feature_importances_))\n",
        "\n",
        "for w in sorted(feature_importance, key=feature_importance.get, reverse=True):\n",
        "    print(w, feature_importance[w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bmZUXbTNJ0C",
        "colab_type": "text"
      },
      "source": [
        "Relativo ai **quattordici giorni precedenti**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMMT7WpBNLjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importance = dict(zip(predictor_columns, best_regressor_0.feature_importances_))\n",
        "\n",
        "for w in sorted(feature_importance, key=feature_importance.get, reverse=True):\n",
        "    print(w, feature_importance[w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VH5XtL-smY4",
        "colab_type": "text"
      },
      "source": [
        "La feature più importante per lo split è stata, senza sorpresa, **\"nuovi_positivi_mean\"**, ossia la media dei nuovi positivi nei 5 giorni precedenti rispetto al giorno di riferimento.\n",
        "\n",
        "La vera sorpresa è stata la feature **\"so2\"**, al secondo posto per importanza, con grande distacco da tutte le altre. L'anidride solforosa sembra avere una **correlazione importante** con i nuovi positivi predetti.\n",
        "\n",
        "Un'ultima osservazione interessante riguarda l'attributo **\"region\"**, che è quello meno importante di tutti. Ciò vuol dire che, con buona probabilità, il modello si comporterà bene anche con **altre zone geografiche**."
      ]
    }
  ]
}